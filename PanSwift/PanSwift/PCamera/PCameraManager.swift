//
//  PCameraManager.swift
//  PanSwift
//
//  Created by Pan on 2022/1/21.
//

import UIKit
import AVFoundation

public protocol CameraManagerDelegate: AnyObject {
    
    /// è§†é¢‘æ•è·è¾“å‡º
    /// - Parameters:
    ///   - sampleBuffer: buffer
    ///   - videoDataOutput: è§†é¢‘output
    func videoCaptureOutput(didOutput sampleBuffer: CMSampleBuffer, fromOutput videoDataOutput: AVCaptureVideoDataOutput)
    
    /// éŸ³é¢‘æ•è·è¾“å‡º
    /// - Parameters:
    ///   - sampleBuffer: buffer
    ///   - audioDataOutput: éŸ³é¢‘output
    func audioCaptureOutput(didOutput sampleBuffer: CMSampleBuffer, fromOutput audioDataOutput: AVCaptureAudioDataOutput)
    
    /// è§†é¢‘å’Œæ·±åº¦æ•°æ®åŒæ­¥è¾“å‡º
    /// - Parameters:
    ///   - videoSampleBuffer: è§†é¢‘æ•°æ®
    ///   - depthPixelBuffer: æ·±åº¦æ•°æ®
    func videoOutputSynchronizer(didOutput videoSampleBuffer: CMSampleBuffer, depthPixelBuffer: CVPixelBuffer)
}

public extension CameraManagerDelegate {
    func videoCaptureOutput(didOutput sampleBuffer: CMSampleBuffer, fromOutput videoDataOutput: AVCaptureVideoDataOutput) {}
    
    func audioCaptureOutput(didOutput sampleBuffer: CMSampleBuffer, fromOutput audioDataOutput: AVCaptureAudioDataOutput) {}
    
    func videoOutputSynchronizer(didOutput videoSampleBuffer: CMSampleBuffer, depthPixelBuffer: CVPixelBuffer) {}
}

public final class PCameraManager: NSObject {

    /// Sessioné…ç½®çŠ¶æ€
    private enum SessionSetupResult {
        case success
        case notAuthorized
        case configurationFailed
        case unknown
    }
    
    // MARK: - Property
    public weak var delegate: CameraManagerDelegate?
    
    /// æ‘„åƒå¤´ç±»å‹
    public var deviceType: AVCaptureDevice.DeviceType = .builtInWideAngleCamera
    
    /// æ‘„åƒå¤´ä½ç½®
    public var devicePosition: AVCaptureDevice.Position = .back
    
    /// å½“å‰ä½¿ç”¨çš„æ‘„åƒå¤´
    private var captureDevice: AVCaptureDevice!
    
    /// è®¾å¤‡ç®¡é“
    private let session = AVCaptureSession()
    
    /// Sessioné…ç½®çŠ¶æ€
    private var setupResult: SessionSetupResult = .success
    
    /// ç”¨äºè®°å½•é…ç½®çš„å¼€å§‹/æäº¤
    private var beginSessionConfigurationCount = 0;
    
    /// é˜Ÿåˆ—
    private let sessionQueue = DispatchQueue(label: "com.pan.cameraManager.sessionQueue")
    private let dataOutputQueue = DispatchQueue(label: "com.pan.cameraManager.videoDataOutputQueue")
    
    private var videoDeviceInput: AVCaptureDeviceInput!
    private let videoDataOutput = AVCaptureVideoDataOutput()
    
    private var audioDeviceInput: AVCaptureDeviceInput!
    private let audioDataOutput = AVCaptureAudioDataOutput()
    
    private let depthDataOutput = AVCaptureDepthDataOutput()
    
    /// åŒæ­¥è§†é¢‘æ•°æ®å’Œæ·±åº¦æ•°æ®çš„è¾“å‡º
    private var outputSynchronizer: AVCaptureDataOutputSynchronizer?
    
    // MARK: - Life Cycle
    override init() {
        super .init()
        
        NotificationCenter.default.addObserver(self, selector: #selector(sessionRuntimeErrorNoti(notification:)), name: NSNotification.Name.AVCaptureSessionRuntimeError, object: session)
        NotificationCenter.default.addObserver(self, selector: #selector(sessionInterruptitedNoti(notification:)), name: NSNotification.Name.AVCaptureSessionWasInterrupted, object: session)
        NotificationCenter.default.addObserver(self, selector: #selector(sessionInterruptionEndedNoti(notification:)), name: NSNotification.Name.AVCaptureSessionInterruptionEnded, object: session)
        NotificationCenter.default.addObserver(self, selector: #selector(sessionDidStopRunningNoti(notification:)), name: NSNotification.Name.AVCaptureSessionDidStopRunning, object: session)
        NotificationCenter.default.addObserver(self, selector: #selector(sessionDidStarRunningNoti(notification:)), name: NSNotification.Name.AVCaptureSessionDidStartRunning, object: session)
        
        sessionQueue.suspend()
        sessionQueue.async {
            self.configSession()
        }
    }
    
    deinit {
        HSLog("ğŸ¤”ğŸ¤”\(Self.self) deinit")
    }
    
    /// å‡†å¤‡
    /// @discussion åœ¨startRunningä¹‹å‰æ‰§è¡Œ
    func prepare() {
        PCameraAuthorization.requestAuthorization(with: .video) { success in
            if success {
                self.setupResult = .success
            }else {
                self.setupResult = .notAuthorized
            }
            // æ‰§è¡Œé˜Ÿåˆ—ä»»åŠ¡
            self.sessionQueue.resume()
        }
    }
    
    /// å¼€å§‹è¿è¡Œ
    func startRunning() {
        guard setupResult == .success else {
            return
        }
        
        sessionQueue.async {
            self.session.startRunning()
        }
    }
    
    /// åœæ­¢è¿è¡Œ
    func stopRunning() {
        guard setupResult == .success else {
            return
        }
        
        sessionQueue.async {
            self.session.stopRunning()
        }
    }
}

// MARK: - Private Method
extension PCameraManager {
    
    /// é…ç½®session
    private func configSession() {
        guard setupResult == .success else {
            return
        }
        
        beginConfiguration()
        defer {
            commitConfiguration()
        }
        
        /// é…ç½®video
        guard let videoDevice = AVCaptureDevice.default(deviceType, for: .video, position: devicePosition) else {
            setupResult = .configurationFailed
            HSLog("ğŸ¤”ğŸ¤”Could not find any video device")
            return
        }
        captureDevice = videoDevice

        do {
            videoDeviceInput = try AVCaptureDeviceInput(device: videoDevice)
        } catch {
            HSLog("ğŸ¤”ğŸ¤”Could not create video device input: \(error)")
            setupResult = .configurationFailed
            return
        }

        guard session.canAddInput(videoDeviceInput) else {
            HSLog("ğŸ¤”ğŸ¤”Could not add video device input to the session")
            setupResult = .configurationFailed
            return
        }
        session.addInputWithNoConnections(videoDeviceInput)

        guard let backInputPort = videoDeviceInput.ports(for: .video, sourceDeviceType: videoDevice.deviceType, sourceDevicePosition: videoDevice.position).first else {
            HSLog("Could not find the back camera device input's video port")
            setupResult = .configurationFailed
            return
        }

        guard session.canAddOutput(videoDataOutput) else {
            HSLog("Could not add the back camera video data output")
            setupResult = .configurationFailed
            return
        }
        session.addOutputWithNoConnections(videoDataOutput)
        videoDataOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey as String: Int(kCVPixelFormatType_32BGRA)]
        videoDataOutput.setSampleBufferDelegate(self, queue: dataOutputQueue)

        let deviceConnection = AVCaptureConnection(inputPorts: [backInputPort], output: videoDataOutput)
        guard session.canAddConnection(deviceConnection) else {
            print("Could not add a connection to the back camera video data output")
            return
        }
        session.addConnection(deviceConnection)
        deviceConnection.videoOrientation = .portrait
        
        /// é…ç½®audio
        guard let audioDevice = AVCaptureDevice.default(for: .audio) else {
            print("Could not find the microphone")
            return
        }
        
        do {
            audioDeviceInput = try AVCaptureDeviceInput(device: audioDevice)
        } catch {
            HSLog("ğŸ¤”ğŸ¤”Could not create video device input: \(error)")
            setupResult = .configurationFailed
            return
        }
        
        guard session.canAddInput(audioDeviceInput) else {
            HSLog("ğŸ¤”ğŸ¤”Could not add audio device input to the session")
            setupResult = .configurationFailed
            return
        }
        session.addInput(audioDeviceInput)
        
        guard session.canAddOutput(audioDataOutput) else {
            HSLog("ğŸ¤”ğŸ¤”Could not add audioDataOutput to the session")
            setupResult = .configurationFailed
            return
        }
        session.addOutput(audioDataOutput)
        audioDataOutput.setSampleBufferDelegate(self, queue: dataOutputQueue)
        
        /// é…ç½®æ·±åº¦é€šé“
        let depthFormats = videoDevice.activeFormat.supportedDepthDataFormats
        let depth32formats = depthFormats.filter({
            CMFormatDescriptionGetMediaSubType($0.formatDescription) == kCVPixelFormatType_DepthFloat16
        })
        
        if depth32formats.isEmpty {
            print("Device does not support Float32 depth format")
            setupResult = .configurationFailed
            return
        }
        
        let selectedFormat = depth32formats.max(by: { first, second in
            CMVideoFormatDescriptionGetDimensions(first.formatDescription).width < CMVideoFormatDescriptionGetDimensions(second.formatDescription).width })
        
        do {
            try videoDevice.lockForConfiguration()
            videoDevice.activeDepthDataFormat = selectedFormat
            videoDevice.unlockForConfiguration()
        } catch  {
            print("Could not lock device for configuration: \(error)")
            setupResult = .configurationFailed
            return
        }
        
        guard session.canAddOutput(depthDataOutput) else {
            print("Could not add depth data output to the session")
            setupResult = .configurationFailed
            return
        }
        session.addOutput(depthDataOutput)
        depthDataOutput.isFilteringEnabled = true
        depthDataOutput.connection(with: .depthData)?.isEnabled = true
        depthDataOutput.connection(with: .depthData)?.videoOrientation = .portrait
        
        /// åŒæ­¥æ•°æ®
        outputSynchronizer = AVCaptureDataOutputSynchronizer(dataOutputs: [videoDataOutput, depthDataOutput])
        outputSynchronizer?.setDelegate(self, queue: dataOutputQueue)
        
//        if AVCaptureDevice.supportDolbyVision() {
//            for format in videoDevice.formats {
//                let description = format.formatDescription
//                if CMFormatDescriptionGetMediaSubType(description) == kCVPixelFormatType_420YpCbCr8BiPlanarFullRange, format.isMultiCamSupported {
//                    do {
//                        try videoDevice.lockForConfiguration()
//                        videoDevice.activeFormat = format
//                        videoDevice.activeVideoMinFrameDuration = CMTimeMake(value: 1, timescale: 30)
//                        videoDevice.activeVideoMaxFrameDuration = CMTimeMake(value: 1, timescale: 30)
//                        /// é‡è®¾é¢œè‰²ç©ºé—´ä¸ºæœ€é«˜æ”¯æŒ
//                        if #available(iOS 10.0, *) {
//                            videoDevice.activeColorSpace = format.supportedColorSpaces.last!;
//                        }
//                        videoDevice.unlockForConfiguration()
//                        break
//                    } catch {
//                        print(error)
//                        return
//                    }
//                }
//            }
//        }
    }
    
    /// å¼€å§‹é…ç½®session
    private func beginConfiguration() {
        beginSessionConfigurationCount+=1
        if beginSessionConfigurationCount == 1 {
            session.beginConfiguration()
        }
    }
    
    /// æäº¤sessioné…ç½®
    private func commitConfiguration() {
        beginSessionConfigurationCount-=1
        if beginSessionConfigurationCount == 0 {
            session.commitConfiguration()
        }
    }
    
    /// è·å–è§†é¢‘é…ç½®
    func videoSetting() -> [String: NSObject]? {
        guard let videoSettings = videoDataOutput.recommendedVideoSettingsForAssetWriter(writingTo: .mov) as? [String: NSObject] else {
            print("Could not get back camera video settings")
            return nil
        }
        
        return videoSettings
    }
    
    /// è·å–éŸ³é¢‘è®¾ç½®
    func audioSetting() -> [String: NSObject]? {
        guard let audioSettings = audioDataOutput.recommendedAudioSettingsForAssetWriter(writingTo: .mov) as? [String: NSObject] else {
            print("Could not get back microphone audio settings")
            return nil
        }
        
        return audioSettings
    }
    
    /// è·å–è§†é¢‘æ—‹è½¬è§’åº¦
    func videoTransform() -> CGAffineTransform? {
        guard let videoConnection = videoDataOutput.connection(with: .video) else {
            print("Could not find the back and front camera video connections")
            return nil
        }
        
        let deviceOrientation = UIDevice.current.orientation
        let videoOrientation = AVCaptureVideoOrientation(deviceOrientation: deviceOrientation) ?? .portrait
        
        // Compute transforms from the back camera's video orientation to the device's orientation
        let backCameraTransform = videoConnection.videoOrientationTransform(relativeTo: videoOrientation)

        return backCameraTransform
    }

}

// MARK: - é€šçŸ¥
extension PCameraManager {
    /// Sessionè¿è¡Œæ—¶é”™è¯¯
    @objc private func sessionRuntimeErrorNoti(notification: Notification) {
//        HSLog("\(notification)")
    }
    
    /// Sessionä¸­æ–­
    @objc private func sessionInterruptitedNoti(notification: Notification) {
//        HSLog("\(notification)")
    }
    
    /// Sessionä¸­æ–­æ¢å¤
    @objc private func sessionInterruptionEndedNoti(notification: Notification) {
//        HSLog("\(notification)")
    }
    
    /// Sessionåœæ­¢è¿è¡Œ
    @objc private func sessionDidStopRunningNoti(notification: Notification) {
//        HSLog("\(notification)")
    }
    
    /// Sessionå¼€å§‹è¿è¡Œ
    @objc private func sessionDidStarRunningNoti(notification: Notification) {
//        HSLog("\(notification)")
    }
}

// MARK: - VideoDataOutputä»£ç†
extension PCameraManager: AVCaptureVideoDataOutputSampleBufferDelegate, AVCaptureAudioDataOutputSampleBufferDelegate {
    public func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
//        HSLog("ğŸ¤”ğŸ¤”\(sampleBuffer)")
        
        if let videoDataOutput = output as? AVCaptureVideoDataOutput {
            connection.videoOrientation = .portrait
            delegate?.videoCaptureOutput(didOutput: sampleBuffer, fromOutput: videoDataOutput)
        } else if let audioDataOutput = output as? AVCaptureAudioDataOutput {
            delegate?.audioCaptureOutput(didOutput: sampleBuffer, fromOutput: audioDataOutput)
        }
    }
    
    public func captureOutput(_ output: AVCaptureOutput, didDrop sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        var reason: CMAttachmentMode = 0
        CMGetAttachment(sampleBuffer, key: kCMSampleBufferAttachmentKey_DroppedFrameReason, attachmentModeOut: &reason)
        HSLog("ğŸ¤”ğŸ¤”\(String(describing: reason))ä¸¢å¸§äº†")
    }
}

// MARK: - Synchronizerä»£ç†
extension PCameraManager: AVCaptureDataOutputSynchronizerDelegate {
    public func dataOutputSynchronizer(_ synchronizer: AVCaptureDataOutputSynchronizer, didOutput synchronizedDataCollection: AVCaptureSynchronizedDataCollection) {
        // Read all outputs
        guard let syncedDepthData = synchronizedDataCollection.synchronizedData(for: depthDataOutput) as? AVCaptureSynchronizedDepthData,
              let syncedVideoData = synchronizedDataCollection.synchronizedData(for: videoDataOutput) as? AVCaptureSynchronizedSampleBufferData else {
            return
        }
        
        if syncedDepthData.depthDataWasDropped || syncedVideoData.sampleBufferWasDropped {
            return
        }
        
        delegate?.videoOutputSynchronizer(didOutput: syncedVideoData.sampleBuffer, depthPixelBuffer: syncedDepthData.depthData.depthDataMap)
    }
}
